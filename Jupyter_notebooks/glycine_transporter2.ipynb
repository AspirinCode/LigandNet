{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smile file generation for actives\n",
    "actives = open('/Users/dshrestha/Desktop/Pharos/ligands_obtained/Sodium__and_chloride_dependent_glycine_transporter_2.txt','r').readlines()\n",
    "active_smiles = open('/Users/dshrestha/Desktop/Pharos/active_glycine_smiles.smi','w')\n",
    "\n",
    "for lines in actives:\n",
    "    line = lines.split('\\t')[0]\n",
    "    active_smiles.write(line+'\\n')\n",
    "\n",
    "active_smiles.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smile file generation for decoys\n",
    "decoy_path ='/Users/dshrestha/Desktop/Pharos/Decoys_set_1/Sodium__and_chloride_dependent_glycine_transporter_2/decoys/'\n",
    "files = os.listdir(decoy_path)\n",
    "decoy_smiles = open('/Users/dshrestha/Desktop/Pharos/decoy_glycine_smiles.smi','w')\n",
    "for file in files:\n",
    "    if file != '.DS_Store':\n",
    "        decoys = open(decoy_path+file,'r').readlines() \n",
    "        for lines in decoys:\n",
    "            if not lines.startswith('ligand'):\n",
    "                line = lines.split('\\t')[0]\n",
    "                decoy_smiles.write(line+'\\n')\n",
    "            else:\n",
    "                decoy_smiles.write(lines.split('\\t')[1]+'\\n')\n",
    "decoy_smiles.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting smiles to sdf\n",
    "def smiles2sdf(input_file, output_file):\n",
    "    os.system('python /Users/dshrestha/Downloads/mayachemtools/bin/RDKitConvertFileFormat.py -i /Users/dshrestha/Desktop/Pharos/'+input_file+' --ov -o /Users/dshrestha/Desktop/Pharos/'+output_file)\n",
    "\n",
    "smiles2sdf('active_glycine_smiles.smi', 'glycine_actives.sdf')\n",
    "smiles2sdf('decoy_glycine_smiles.smi', 'glycine_decoys.sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating features for actives\n",
    "#command='perl  /Users/dshrestha/Downloads/mayachemtools/bin/TopologicalPharmacophoreAtomTripletsFingerprints.pl -r /Users/dshrestha/Desktop/Pharos/glycineActivesTPATF --AtomTripletsSetSizeToUse FixedSize -v ValuesString -o /Users/dshrestha/Desktop/Pharos/glycine_actives.sdf'\n",
    "#os.system(command)\n",
    "\n",
    "active = open('/Users/dshrestha/Desktop/Pharos/fingerprints/glycineActivesTPATF.csv','r').readlines()\n",
    "frame1=[]\n",
    "for lines in active:\n",
    "    #print(lines)\n",
    "    if 'Cmpd' in lines:\n",
    "        #i = re.findall(r'\\d+', lines)\n",
    "        #val=(data.iloc[(int(i[0])-1), 3])\n",
    "        line = lines.split(';')[5].rstrip('\"\\n').split(' ')\n",
    "        #print(len(line))\n",
    "        df = pd.DataFrame(np.array(line).reshape(1,len(line)))\n",
    "        df.astype(int)\n",
    "        frame1.append(df)\n",
    "active_val = [1]*len(frame1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fingerprint generation for decoys\n",
    "command2='perl  /Users/dshrestha/Downloads/mayachemtools/bin/TopologicalPharmacophoreAtomTripletsFingerprints.pl -r /Users/dshrestha/Desktop/Pharos/glycineDecoysTPATF --AtomTripletsSetSizeToUse FixedSize -v ValuesString -o /Users/dshrestha/Desktop/Pharos/glycine_decoys.sdf'\n",
    "os.system(command2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fingerprint generation for decoys\n",
    "decoy = open('/Users/dshrestha/Desktop/Pharos/fingerprints/glycineDecoysTPATF.csv','r').readlines()\n",
    "frame2 =[]\n",
    "for lines in decoy:\n",
    "    #print(lines)\n",
    "    if 'Cmpd' in lines:\n",
    "        #i = re.findall(r'\\d+', lines)\n",
    "        #val=(data.iloc[(int(i[0])-1), 3])\n",
    "        line = lines.split(';')[5].rstrip('\"\\n').split(' ')\n",
    "        #print(len(line))\n",
    "        df = pd.DataFrame(np.array(line).reshape(1,len(line)))\n",
    "        df.astype(int)\n",
    "        frame2.append(df)\n",
    "decoy_val = [0]*len(frame2)\n",
    "#frames = frame1 + frame2\n",
    "#x = pd.concat(frame1, frame2)\n",
    "#values = active_val+decoy_val\n",
    "#y = pd.DataFrame(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4444\n",
      "(4444, 4444)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining actives and decoys for data splitting\n",
    "frames = frame1+frame2\n",
    "len(frames)\n",
    "x = pd.concat(frames)\n",
    "#x.to_csv('/Users/dshrestha/Desktop/Pharos/activefingerprints_glycine.csv', sep=',')\n",
    "values = active_val+decoy_val\n",
    "print(len(values))\n",
    "y = pd.DataFrame(values)\n",
    "print(len(x), len(y))\n",
    "len(active_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the dataset into train and split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20)\n",
    "list(y_test.values.flatten()).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dew =list(y_train.values.flatten())\n",
    "dew.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test:', 0.73047292143401987)\n",
      "('train:', 0.83692456428457906)\n",
      "[[869   5]\n",
      " [  8   7]]\n",
      "\n",
      "\n",
      "('sensitivity: ', 0.4666666666666667)\n",
      "('specificity: ', 0.994279176201373)\n",
      "('PPV: ', 0.5833333333333334)\n"
     ]
    }
   ],
   "source": [
    "#support vector classification\n",
    "\n",
    "#t = (np.array(y_train).ravel())\n",
    "\n",
    "classifier = SVC(C=100.0, kernel ='linear', degree=5, gamma=0.3, coef0=0.0, shrinking=True, \n",
    "                 probability=True, tol=0.003, cache_size=200, class_weight=None, verbose=False, \n",
    "                 max_iter=-1, decision_function_shape='ovo', random_state=None)\n",
    "#classifier = SVC(kernel ='linear', probability=True)\n",
    "classifier.fit(x_train, y_train)\n",
    "y_predicted = classifier.predict(x_test)\n",
    "train_pred = classifier.predict(x_train)\n",
    "\n",
    "train_score= roc_auc_score(y_train, train_pred)\n",
    "test_score = roc_auc_score(y_test, y_predicted)\n",
    "\n",
    "train_score2= roc_auc_score(y_train, pd.DataFrame(train_pred))\n",
    "test_score2 = roc_auc_score(y_test, (y_predicted))\n",
    "\n",
    "print('test:', test_score)\n",
    "print('train:', train_score)\n",
    "\n",
    "#print('test2:', test_score)\n",
    "#print('train2:', train_score)\n",
    "\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "print('\\n')\n",
    "#print(t)\n",
    "y_predicted = map(int, y_predicted)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n",
    "sensitivity = float(tp)/(tp+fn)\n",
    "specificity = float(tn)/(tn+fp)\n",
    "PPV = float(tp)/(tp+fp)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "print('PPV: ', PPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deepchem/lib/python2.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test:', 0.73218916857360794)\n",
      "('train:', 0.84841010224082214)\n",
      "[[872   2]\n",
      " [  8   7]]\n",
      "\n",
      "\n",
      "('sensitivity: ', 0.4666666666666667)\n",
      "('specificity: ', 0.9977116704805492)\n",
      "('PPV: ', 0.7777777777777778)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classification\n",
    "\n",
    "RandomClassifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy')\n",
    "RandomClassifier.fit(x_train, y_train)\n",
    "\n",
    "y_predicted = RandomClassifier.predict(x_test)\n",
    "train_pred = RandomClassifier.predict(x_train)\n",
    "\n",
    "train_score= roc_auc_score(y_train, pd.DataFrame(train_pred))\n",
    "test_score = roc_auc_score(y_test, (y_predicted))\n",
    "\n",
    "print('test:', test_score)\n",
    "print('train:', train_score)\n",
    "\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "print('\\n')\n",
    "#print(t)\n",
    "y_predicted = map(int, y_predicted)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n",
    "sensitivity = float(tp)/(tp+fn)\n",
    "specificity = float(tn)/(tn+fp)\n",
    "PPV = float(tp)/(tp+fp)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "print('PPV: ', PPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.893782777984\n",
      "0.897139588101\n",
      "[[869   5]\n",
      " [  3  12]]\n",
      "\n",
      "\n",
      "('sensitivity: ', 0.8)\n",
      "('specificity: ', 0.994279176201373)\n",
      "('PPV: ', 0.7058823529411765)\n",
      "[[3501   11]\n",
      " [   9   34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Lmodel = LogisticRegression(solver='liblinear', class_weight='balanced', multi_class='ovr',dual=True, C=100, max_iter=100)\n",
    "Lmodel.fit(x_train, y_train)\n",
    "\n",
    "y_predicted = Lmodel.predict(x_test)\n",
    "train_pred = Lmodel.predict(x_train)\n",
    "\n",
    "train_score = roc_auc_score(y_train, train_pred)\n",
    "test_score = roc_auc_score(y_test, y_predicted)\n",
    "\n",
    "print(train_score)\n",
    "print(test_score)\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "print('\\n')\n",
    "y_predicted = map(int, y_predicted)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n",
    "sensitivity = float(tp)/(tp+fn)\n",
    "specificity = float(tn)/(tn+fp)\n",
    "PPV = float(tp)/(tp+fp)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "print('PPV: ', PPV)\n",
    "\n",
    "print(confusion_matrix(y_train, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/deepchem/lib/python2.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99729498861\n",
      "0.897711670481\n",
      "[[870   4]\n",
      " [  3  12]]\n",
      "\n",
      "\n",
      "('sensitivity: ', 0.8)\n",
      "('specificity: ', 0.9954233409610984)\n",
      "('PPV: ', 0.75)\n",
      "[[3493   19]\n",
      " [   0   43]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "extra = ExtraTreesClassifier(n_estimators=100, max_features= None, criterion='entropy', bootstrap=True, oob_score=True, \n",
    "                             warm_start = True, class_weight ='balanced')\n",
    "extra.fit(x_train, y_train)\n",
    "\n",
    "y_predicted = extra.predict(x_test)\n",
    "train_pred = extra.predict(x_train)\n",
    "\n",
    "train_score = roc_auc_score(y_train, train_pred)\n",
    "test_score = roc_auc_score(y_test, y_predicted)\n",
    "\n",
    "print(train_score)\n",
    "print(test_score)\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "print('\\n')\n",
    "y_predicted = map(int, y_predicted)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n",
    "sensitivity = float(tp)/(tp+fn)\n",
    "specificity = float(tn)/(tn+fp)\n",
    "PPV = float(tp)/(tp+fp)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "print('PPV: ', PPV)\n",
    "\n",
    "print(confusion_matrix(y_train, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767441860465\n",
      "0.766666666667\n",
      "[[874   0]\n",
      " [  7   8]]\n",
      "\n",
      "\n",
      "('sensitivity: ', 0.5333333333333333)\n",
      "('specificity: ', 1.0)\n",
      "('PPV: ', 1.0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "estimators = []\n",
    "\n",
    "estimators.append(('logistic', Lmodel))\n",
    "#estimators.append(('svm', classifier))\n",
    "estimators.append(('RF', extra))\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "ensemble.fit(x_train, y_train)\n",
    "\n",
    "y_predicted = ensemble.predict(x_test)\n",
    "train_pred = ensemble.predict(x_train)\n",
    "\n",
    "train_score = roc_auc_score(y_train, train_pred)\n",
    "test_score = roc_auc_score(y_test, y_predicted)\n",
    "\n",
    "print(train_score)\n",
    "print(test_score)\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "print('\\n')\n",
    "y_predicted = map(int, y_predicted)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n",
    "sensitivity = float(tp)/(tp+fn)\n",
    "specificity = float(tn)/(tn+fp)\n",
    "PPV = float(tp)/(tp+fp)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "print('PPV: ', PPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3512    0]\n",
      " [  20   23]]\n",
      "\n",
      "\n",
      "('sensitivity: ', 0.5348837209302325)\n",
      "('specificity: ', 1.0)\n",
      "('PPV: ', 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, train_pred))\n",
    "print('\\n')\n",
    "train_pred = map(int, train_pred)\n",
    "tn1, fp1, fn1, tp1 = confusion_matrix(y_train, train_pred).ravel()\n",
    "sensitivity = float(tp1)/(tp1+fn1)\n",
    "specificity = float(tn1)/(tn1+fp1)\n",
    "PPV = float(tp1)/(tp1+fp1)\n",
    "print('sensitivity: ', sensitivity)\n",
    "print('specificity: ', specificity)\n",
    "print('PPV: ', PPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "pkl_filename = \"/Users/dshrestha/Desktop/Pharos/Models/extra_tree_glycine_transporter2.pkl\"\n",
    "pickle.dump(extra, open(pkl_filename, 'wb'))\n",
    "#with open(pkl_filename, 'wb') as file:\n",
    "#    pickle.dump(classifier, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
